{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "pd.options.display.max_rows = 4000\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60508, 6)\n",
      "politics          22182\n",
      "entertainment      9671\n",
      "comedy             2859\n",
      "the worldpost      2856\n",
      "queer voices       2736\n",
      "sports             2625\n",
      "black voices       2239\n",
      "weird news         1858\n",
      "world news         1762\n",
      "crime              1591\n",
      "media              1574\n",
      "women              1562\n",
      "arts & culture     1243\n",
      "business           1220\n",
      "tech                982\n",
      "green               732\n",
      "science             687\n",
      "latino voices       685\n",
      "religion            675\n",
      "impact              641\n",
      "education           128\n",
      "Name: category, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>crime</td>\n",
       "      <td>DENTON, Texas ― Amanda Painter sat at the kitc...</td>\n",
       "      <td>05/26/2018</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>The 2018 FIFA World Cup starts June 14 in Russ...</td>\n",
       "      <td>05/26/2018</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "\n",
       "                                            subtitle       category  \\\n",
       "0  She left her husband. He killed their children...          crime   \n",
       "1                           Of course it has a song.  entertainment   \n",
       "\n",
       "                                                text        date  \\\n",
       "0  DENTON, Texas ― Amanda Painter sat at the kitc...  05/26/2018   \n",
       "1  The 2018 FIFA World Cup starts June 14 in Russ...  05/26/2018   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.huffingtonpost.com/entry/texas-ama...  \n",
       "1  https://www.huffingtonpost.com/entry/will-smit...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/news.csv')\n",
    "df = df.dropna(subset=['title', 'subtitle', 'text'])\n",
    "print(df.shape)\n",
    "print(df.category.value_counts())\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/victor/.cache/torch/hub/huggingface_pytorch-transformers_master\n"
     ]
    }
   ],
   "source": [
    "#tokenizer = torch.hub.load('huggingface/pytorch-pretrained-BERT', 'gpt2Tokenizer', 'gpt2')\n",
    "#tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'gpt2')\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers:1.2.0', 'tokenizer', 'gpt2-medium')\n",
    "#tokenizer.add_tokens(['$TITLE$', '$SUBTITLE$', '$BODY$'])\n",
    "#tokens = tokenizer.encode(\"$TITLE$ $SUBTITLE$ $BODY$\")\n",
    "#tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3600 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2423 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1486 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1294 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1296 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1322 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1518 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1294 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2430 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1375 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1296 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1590 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1786 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1452 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2410 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1305 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1268 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1296 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1923 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1423 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1421 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1996 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2568 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3392 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1921 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1163 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1440 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3573 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1685 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1538 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1385 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1408 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1722 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2550 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1601 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1163 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1920 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2010 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5992 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6631 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1674 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1395 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1567 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2845 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1707 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1569 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1634 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7375 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1391 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1295 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1554 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1704 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1830 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3567 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1878 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1831 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1844 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1704 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1721 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1773 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1982 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1433 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1610 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1526 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1497 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5277 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1774 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1805 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3645 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3614 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2668 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1836 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3442 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1641 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1697 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1680 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1589 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1295 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2000 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1372 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1616 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1480 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1429 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1491 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3688 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1844 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2644 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1523 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1292 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1945 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1758 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1466 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1905 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1642 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1393 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1783 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1712 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3358 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1694 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3511 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1598 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1514 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1750 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1850 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2622 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3909 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1773 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1404 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3310 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2678 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1701 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1642 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1535 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1558 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1377 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1575 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5514 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7309 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1800 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1621 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1414 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1868 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1717 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1910 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1711 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1837 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (18629 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2909 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1461 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1563 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1587 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4480 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1699 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1836 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1836 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2456 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1799 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1421 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1420 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1421 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2822 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2664 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1410 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1697 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1416 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1322 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1679 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4423 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1486 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7457 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1696 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6935 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3404 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1964 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1857 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1562 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1943 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1826 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1336 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1423 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1416 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1319 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6568 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1752 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1827 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1943 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1513 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1526 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1419 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1682 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1513 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1708 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1412 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3408 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1870 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2705 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1765 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1873 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3612 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1840 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1509 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3608 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2894 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1375 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1435 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2405 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2746 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1824 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1420 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1718 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1984 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1597 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1647 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4934 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1707 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1951 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1948 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1622 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2563 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1383 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2553 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1860 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1419 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1675 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1545 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1681 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2561 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1656 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1579 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1916 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1614 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2498 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1462 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1686 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1723 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1440 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2008 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1453 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3636 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1558 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1776 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1614 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3407 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1522 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1340 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4572 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4805 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2826 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1886 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1409 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1532 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1753 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4778 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1745 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1622 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1564 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3694 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1540 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1586 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1963 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2503 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1722 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1716 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1843 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2393 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1919 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3406 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1309 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1728 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1680 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2743 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1417 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1460 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1323 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1434 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1999 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3713 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1778 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1847 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1420 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1899 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1764 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1676 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1798 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1319 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2314 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1411 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5491 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4487 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1840 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1836 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1440 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1740 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1499 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1682 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1488 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1875 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2860 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3793 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1688 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4405 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1369 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1751 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1847 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1907 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1461 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1838 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2591 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1838 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2271 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1295 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1645 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1734 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1668 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1763 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1732 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1797 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1638 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4215 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2630 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1937 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1812 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1619 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2235 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6455 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2332 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2583 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1531 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1408 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1663 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1469 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1775 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1681 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1763 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1414 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2739 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1354 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1880 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3615 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1812 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1731 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1895 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1672 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3918 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3640 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1928 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2814 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1511 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2381 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2996 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1343 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1709 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1507 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1551 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1673 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1986 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1869 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2405 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1467 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1446 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1795 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1375 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1490 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1637 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1427 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1498 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1825 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2730 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1624 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1546 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1411 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2617 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1399 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1741 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1927 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1759 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1742 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1688 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1759 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1690 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1467 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2516 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1568 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1715 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2490 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2525 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2011 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1879 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1751 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1912 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1892 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1674 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1648 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1483 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1526 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1627 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1623 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3691 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3422 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2787 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1469 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1488 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1688 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1705 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1301 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1516 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1976 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1894 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1517 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1838 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2393 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1573 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3568 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1781 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1565 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1753 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2794 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2790 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1580 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1815 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1597 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1795 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2808 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2312 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1840 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1276 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1533 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1516 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1371 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1484 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1735 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1425 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1617 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1677 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2672 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1813 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1897 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1301 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1793 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1909 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3675 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1860 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1879 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1815 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1824 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1382 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1994 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7072 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1434 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1616 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4962 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1511 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1820 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7639 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1480 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1859 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1924 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1427 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1788 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1658 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1607 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1733 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1777 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1651 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2630 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2449 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1502 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1590 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2974 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1395 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1724 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1509 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1898 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1934 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1837 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1995 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1346 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3629 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1510 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1803 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3558 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2844 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1986 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1621 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2960 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1599 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1489 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1550 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1655 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2750 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2008 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3301 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1581 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1660 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2010 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1677 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3864 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1635 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2617 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2346 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1268 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1658 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1500 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3938 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2693 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1375 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1716 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1573 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1387 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2888 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (9812 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1569 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3452 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1489 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1909 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1957 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1766 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2738 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1884 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1322 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1417 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1504 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2029 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1544 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1594 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1950 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1776 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1811 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1302 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1540 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1854 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1777 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1399 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1450 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2529 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1835 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2707 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1643 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3561 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2221 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1716 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1572 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2759 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1517 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4673 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1688 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1655 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1931 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1678 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1695 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1970 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2504 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1563 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1842 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2414 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1438 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1584 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1605 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1662 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2870 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5399 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1460 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1469 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1485 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2457 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1421 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1765 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1553 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1480 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1776 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1305 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1912 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1459 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2395 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2278 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1716 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3019 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1468 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4889 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1346 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1910 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1903 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7775 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1358 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1707 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1867 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1414 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1768 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1296 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1545 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1685 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1537 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1314 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1683 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1877 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5765 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1892 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1658 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4554 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3017 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1634 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1482 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1585 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1550 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1634 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2393 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1438 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1905 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1402 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1399 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1661 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1519 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1243 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2012 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1414 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1725 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1475 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1517 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1767 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3546 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1680 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1652 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1515 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1451 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1458 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2597 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1491 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2985 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1962 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2919 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1514 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1628 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1865 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1787 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2709 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1343 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1442 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (8564 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1800 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3674 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1820 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1764 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1733 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1570 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1675 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2703 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1509 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6517 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1468 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1693 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1842 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1419 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1926 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1688 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1558 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1825 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1819 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1794 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1962 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1901 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (9282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1410 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2631 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3889 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2000 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1525 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1819 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1779 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1777 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4009 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1989 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3517 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2605 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1798 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1821 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1534 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1779 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1787 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4699 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1406 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1744 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1340 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1535 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1786 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1423 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2897 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2443 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1557 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1586 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1940 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1633 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1826 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2755 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1797 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1947 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1948 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2821 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1816 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1402 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1312 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1868 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1717 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1770 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1631 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1656 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2022 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1392 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1615 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1999 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1737 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1692 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2769 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1421 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1367 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1520 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1696 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2425 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1541 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1569 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2502 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1769 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3017 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1702 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1369 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1346 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1624 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1901 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1663 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1646 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2621 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1720 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2435 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1489 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1243 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1977 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1753 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1788 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1751 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1450 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1392 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2530 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2957 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1575 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1583 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1446 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1760 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1411 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5699 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1268 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1258 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1683 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1979 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1584 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1292 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1887 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3317 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2744 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1948 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1895 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1457 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1824 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1949 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1657 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1826 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1707 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1356 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2356 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1596 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1394 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1989 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1537 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1495 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1750 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1632 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1717 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2421 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3560 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1772 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1582 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1509 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1940 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1568 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1533 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1507 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1533 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1419 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1940 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2557 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1523 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3796 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1556 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1301 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1785 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1854 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4928 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3686 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1550 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1577 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2478 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1846 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2377 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2023 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1469 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3418 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1548 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2902 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1686 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1521 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2824 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1542 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4974 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2007 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1743 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2334 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3846 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1589 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1438 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1681 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1970 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1835 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3411 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1309 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1995 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1982 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1809 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1702 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1765 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1899 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1475 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1554 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1809 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1771 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1751 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1309 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4858 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1700 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1997 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1393 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3939 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1902 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2491 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1473 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1923 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1862 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2551 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1469 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4748 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2667 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3653 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1463 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5355 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1377 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1498 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1470 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2931 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2683 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1309 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1405 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2614 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1354 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1773 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1844 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1582 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1551 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1421 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1797 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1673 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1630 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1468 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1632 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2664 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1588 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1739 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1830 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1371 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1653 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1674 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1737 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1377 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1739 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5385 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3926 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1346 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1810 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1699 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3815 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1871 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1735 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1656 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2647 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1433 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1610 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1707 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2972 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1736 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2885 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2436 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1296 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1549 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7422 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1865 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2440 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1479 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1437 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1991 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1741 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2836 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2598 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2016 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1406 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1740 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1705 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1889 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6760 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1874 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1371 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4516 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3909 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1799 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1409 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1569 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1310 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1645 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1525 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1798 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1602 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1853 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1825 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2797 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1551 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1544 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1646 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1393 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1860 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1875 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1795 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1543 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1416 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2377 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3940 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1608 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4934 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1305 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1517 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2705 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1704 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1536 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2752 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1921 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1620 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2812 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1709 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1684 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2484 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3725 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4681 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1283 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1520 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1950 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1980 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1942 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1537 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2638 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1571 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1485 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1377 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2413 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1481 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1769 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2475 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2376 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1649 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1417 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4616 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2591 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1708 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2878 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1603 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1639 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2452 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3523 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1363 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1553 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1908 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1562 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1953 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1324 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1735 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1510 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1693 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1798 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1666 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2452 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2878 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1994 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1908 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1795 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3831 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1463 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1662 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1895 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1567 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3339 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1660 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1836 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1689 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1679 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1599 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1719 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1459 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1828 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1762 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1754 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1424 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1707 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4349 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1711 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1540 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (8075 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2385 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1563 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1564 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1499 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1470 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1664 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2768 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1921 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1882 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1918 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1787 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1851 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1463 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2475 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1547 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1451 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1672 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1683 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1424 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1683 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1424 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2304 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1866 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1763 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1991 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2251 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1556 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2021 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1985 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1551 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3256 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1749 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2431 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1490 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2018 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2894 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1394 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1830 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1418 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1563 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1486 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2406 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1576 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1310 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1419 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1513 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3525 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1243 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1661 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1879 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2034 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1592 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1521 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1547 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2446 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1391 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1346 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5957 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1810 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1523 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1883 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1459 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1559 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1479 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1457 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1737 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1444 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1906 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2746 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1480 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1647 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1586 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1385 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1629 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1705 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1499 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1685 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1355 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1878 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1557 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1326 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1805 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1610 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1791 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2021 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2322 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3815 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3452 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1380 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1649 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1722 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2573 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2772 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1558 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2646 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4730 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1874 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2927 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1377 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1550 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1827 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3709 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3342 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1959 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1520 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1878 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1302 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1577 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1657 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1864 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1340 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1363 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1163 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1302 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1536 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1578 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1607 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1824 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1748 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1558 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1628 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4536 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1528 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1822 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1805 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1355 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1574 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1662 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1556 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1999 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1363 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1612 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1664 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1354 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2003 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1613 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1957 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1598 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1640 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1283 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3720 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1987 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1394 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4243 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1511 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1563 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1324 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1971 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1982 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2716 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1544 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2014 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1909 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1582 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1515 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1930 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2485 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1687 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1296 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1802 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1440 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1367 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5056 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1642 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1775 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1516 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1859 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1395 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1798 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1795 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4814 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1613 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1709 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1663 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1926 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1559 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1687 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1835 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1434 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1424 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1944 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1258 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2462 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1413 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1873 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2908 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1653 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2632 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1593 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1544 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1792 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3922 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1878 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1882 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1891 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3744 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1585 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1822 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1944 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3022 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1844 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3853 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1438 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1602 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1603 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1650 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1444 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1444 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4897 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1923 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1370 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1841 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1850 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2669 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1580 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1838 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1613 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1674 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1446 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2305 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1405 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1669 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1603 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3608 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2825 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1547 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1764 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1363 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2207 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1301 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1488 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3843 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1489 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1645 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1309 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1377 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1855 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1517 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1589 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2681 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1301 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1467 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1652 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1292 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1569 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1533 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2396 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1596 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1965 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1383 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1377 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2689 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2462 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1377 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1460 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1841 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4862 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1732 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1380 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1905 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1371 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1672 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1866 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1502 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1825 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3855 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1363 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1458 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1664 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1648 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1800 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1638 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1607 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1681 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1433 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2481 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1602 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4275 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1550 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1426 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1369 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1433 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1857 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2548 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1996 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1821 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2558 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1954 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1782 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1861 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1560 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3796 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1613 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7304 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1481 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4577 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1758 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1670 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1520 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1688 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1525 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2015 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6788 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2338 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1498 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2462 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1295 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1593 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1651 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2066 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1504 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3953 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2001 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1430 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1502 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2350 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1712 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2413 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5828 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1640 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1530 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1527 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1681 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1163 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1695 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1564 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1387 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2446 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1430 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1720 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1385 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1630 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1529 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1624 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1616 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1965 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4556 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1409 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1669 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1660 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1586 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1652 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3875 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1599 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1702 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1473 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1567 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1276 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2575 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1477 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2007 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1494 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1444 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1743 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2464 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1283 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1515 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1485 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1455 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1680 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1802 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1828 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1604 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2620 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1413 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1853 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1336 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1583 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1665 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2446 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1969 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1495 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1357 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1449 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1942 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1893 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1713 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1698 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1750 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1489 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4602 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4669 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1596 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1834 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1383 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1957 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2678 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1899 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1770 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1627 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1297 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2008 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1544 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2372 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2017 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1399 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1422 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1463 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1643 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1488 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1684 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4341 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1870 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1788 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2276 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2409 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1674 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1644 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1458 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1456 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1301 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1494 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1819 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1921 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2396 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1983 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1739 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1581 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1481 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1566 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1721 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2599 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1358 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1690 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1343 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1323 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1578 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2829 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1533 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1540 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1788 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1533 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1435 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1450 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4897 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1495 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1687 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1577 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1391 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1592 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1734 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3940 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1530 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3564 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1482 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2773 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1553 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2291 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3755 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1946 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1631 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1402 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1382 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1741 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1453 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1526 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2588 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1430 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1827 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1862 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1606 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2521 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1958 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1703 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1326 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1896 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1671 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1343 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1980 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1493 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1693 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1949 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2827 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3677 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1587 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2460 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2305 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1357 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1682 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2228 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2814 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1302 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1777 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1737 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1358 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1705 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1615 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1455 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1391 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1625 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5696 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1312 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1466 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1525 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1924 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2010 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1925 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1565 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1786 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1497 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1336 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1294 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1936 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1627 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4579 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1504 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1607 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1507 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1725 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1297 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1370 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2044 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1959 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2363 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1502 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4829 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1372 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1763 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1777 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1322 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1782 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3411 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1712 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1640 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2176 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2615 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1539 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5733 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1409 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3296 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1697 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2221 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1367 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1370 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1449 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1356 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2651 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2662 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1962 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1728 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2420 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1658 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1513 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1477 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1912 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1720 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3014 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4787 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1844 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6536 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1615 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1412 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1745 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1862 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1843 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2520 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1645 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1696 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1496 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1629 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2383 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1932 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1355 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1794 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2312 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1539 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1596 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1800 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1555 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2747 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1573 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2680 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1489 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1633 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1276 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1616 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2615 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1625 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1522 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1947 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2297 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3850 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1541 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1474 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1998 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1982 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1603 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1698 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1980 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1986 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1553 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1697 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1843 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1363 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1593 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1658 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1336 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1939 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1727 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1518 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2381 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2271 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1539 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1395 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1693 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2292 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1473 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1701 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1628 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1631 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1294 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1438 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1612 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (12185 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1951 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1539 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2017 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1395 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1490 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1619 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1975 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1999 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1710 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1283 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1713 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3970 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1672 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1972 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1494 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2294 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1410 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2761 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1581 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1408 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1788 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1814 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1860 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1457 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1562 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1500 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1363 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1649 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1632 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2627 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1685 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1738 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2461 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2292 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2608 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1810 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1268 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1562 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1715 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1584 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1464 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2667 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2314 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1918 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2340 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1358 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1999 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1465 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1959 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1523 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1855 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1492 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1523 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2334 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1425 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2463 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2498 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1715 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2018 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1442 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1367 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5922 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1785 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1647 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1565 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2011 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1518 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1488 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1432 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1531 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1607 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1520 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1884 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1576 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1472 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2424 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1990 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (8170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1960 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1557 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1813 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1940 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2014 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1377 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1391 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1422 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5114 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1744 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1531 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1911 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1522 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1643 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1821 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1683 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2385 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1798 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2715 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1324 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1322 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1466 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1446 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1283 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1687 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3999 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1663 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1485 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1367 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2866 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1647 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2015 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1312 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1873 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1467 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1283 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1380 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1807 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2480 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2478 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2839 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1310 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3736 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1581 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1527 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1258 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2561 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1756 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1355 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1741 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1757 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1577 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1399 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1628 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1978 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1806 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1884 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1467 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1731 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2573 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2382 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1484 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1513 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1437 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1533 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1981 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2486 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1653 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2380 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1395 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1833 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1584 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1638 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1560 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1488 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1790 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1630 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2942 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2588 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1532 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1910 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1566 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2576 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2207 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1412 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2242 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2513 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1861 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3312 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1769 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1647 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1536 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1514 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1382 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2431 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1435 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4419 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1326 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1999 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2639 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1336 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1751 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1650 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1743 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1392 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1424 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4610 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1382 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1684 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1762 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1808 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1940 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1405 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1485 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1815 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1355 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1301 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1691 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1367 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2277 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1496 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1392 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1609 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1302 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2375 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1357 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1567 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1553 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2015 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2761 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1456 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2527 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2984 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2634 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1918 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2340 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1788 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3526 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1753 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2984 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1395 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2848 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1383 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2535 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1982 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1416 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1276 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2573 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1432 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1492 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1673 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1619 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1707 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1486 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3470 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1934 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2588 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1369 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1495 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1734 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1383 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2874 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1848 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1511 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2559 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1667 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3939 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1302 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1682 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1346 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1613 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1411 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1435 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1951 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1816 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1404 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3909 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1601 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1508 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1798 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1757 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4485 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1968 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1258 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1479 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1941 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1421 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2701 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1979 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1689 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4493 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1961 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1372 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1551 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1763 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2588 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1319 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2678 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1836 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1772 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1461 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1994 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5355 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1481 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1540 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1733 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1663 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1163 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1723 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1795 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1869 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1460 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1745 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1781 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1873 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1991 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1369 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1830 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2751 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1678 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1632 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1828 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2802 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (11944 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1811 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1519 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4581 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1837 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2005 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1610 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2566 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2625 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1510 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1916 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1831 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1967 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1890 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1276 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1635 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1924 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2679 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2578 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2880 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1530 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1984 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1424 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2767 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1563 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1532 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1556 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1369 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1522 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2325 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1631 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4543 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1575 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1782 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1658 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2766 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1609 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2644 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1570 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2409 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1944 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1451 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1438 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1562 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1939 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3915 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1905 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1916 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1600 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2677 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1428 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1420 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1268 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1557 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2310 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1402 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1659 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1658 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1937 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2855 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1437 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1339 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1647 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1684 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1649 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1489 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5676 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1504 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2868 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1800 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2483 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2988 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1527 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1372 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1650 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1685 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3404 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1473 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1435 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1560 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2147 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1952 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1358 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1783 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2794 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3982 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1399 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1875 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1870 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1959 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1914 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1427 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1632 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2738 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1785 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1944 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1305 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1683 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1435 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1655 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1399 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1920 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1369 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1508 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1582 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2418 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1799 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1478 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1416 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1524 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1827 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4684 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2412 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2363 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2003 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2516 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1970 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2513 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1422 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1354 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1806 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1716 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1710 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4779 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1593 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1297 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1575 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1936 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1310 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1399 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1919 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1464 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1356 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1773 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3000 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1915 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1670 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1500 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1761 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1520 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1805 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1972 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1457 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2761 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1402 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1391 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1301 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1767 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1553 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1949 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1813 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1599 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1911 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1547 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2470 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1749 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2622 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1621 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2792 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1402 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3488 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1651 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1910 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1301 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1618 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2478 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1566 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1715 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1882 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1482 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3324 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1624 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2604 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1766 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1999 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1485 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1382 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1896 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1375 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1516 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1420 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1553 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1546 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1453 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1583 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1446 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1596 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4511 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1630 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2409 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2315 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1430 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2587 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1641 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2502 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1535 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1395 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2488 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1784 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1775 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1559 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1578 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1483 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1945 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2579 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1529 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1425 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4924 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2018 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1418 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1515 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1310 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1629 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1399 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1841 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1513 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3466 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2886 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1426 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2487 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1536 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1974 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1453 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1474 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1900 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1459 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2383 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1634 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3004 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2569 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1453 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1372 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1408 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1546 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3775 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1486 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1792 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1425 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1465 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2803 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1599 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2947 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1417 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1799 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2089 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1817 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1336 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2730 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1785 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3930 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1369 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1276 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1817 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2595 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1552 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1515 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2611 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1743 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1354 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1296 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1646 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1354 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1603 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1668 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1530 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1607 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1495 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1798 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2873 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1522 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1605 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3000 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1933 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1450 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1375 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1387 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1903 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1491 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2706 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4024 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3890 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2693 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1968 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1974 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1490 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1538 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1567 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2968 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2960 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2409 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2654 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2334 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1565 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1243 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1510 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1446 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1477 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1707 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1949 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3661 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2594 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1744 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1663 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1696 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2534 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1593 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1437 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1435 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1550 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1597 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1784 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1417 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1755 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1463 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1464 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2022 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3727 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2337 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1431 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1496 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1535 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1831 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2674 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3596 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1585 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1542 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1880 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4692 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1460 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1572 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1911 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1438 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1712 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1994 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4612 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2740 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1358 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1677 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5303 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1652 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1336 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1413 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1508 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2529 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1530 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1503 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1528 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2957 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1682 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1850 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1993 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1559 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1605 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1918 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1502 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1906 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1357 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1520 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1920 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1410 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2679 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2908 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1568 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1883 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1994 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1822 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1753 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1411 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1981 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1878 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1629 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4827 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1948 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2350 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2713 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1479 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1467 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1584 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1919 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1507 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1858 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5753 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1619 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1694 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1496 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2015 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2775 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1357 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1706 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1524 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1492 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1544 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2989 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1312 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2975 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1887 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1754 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1645 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1513 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1339 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1437 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1377 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1857 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1609 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1323 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1297 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2615 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2699 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1718 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1628 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1738 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1367 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1490 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1475 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1749 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1543 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1346 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1747 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1651 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2822 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1788 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1449 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1664 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1666 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1336 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1746 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1409 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1322 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1947 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2077 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1482 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3009 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1394 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1585 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2243 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1791 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2427 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1976 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2316 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2764 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1642 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1343 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2312 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1715 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1787 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2383 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1953 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1483 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1645 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1421 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1302 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1839 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1830 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1783 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1324 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1444 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1305 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2906 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1442 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1733 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1482 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1647 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2717 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1416 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1706 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1551 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1525 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1582 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1835 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1531 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1520 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5753 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2519 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1295 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1976 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1482 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2911 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4560 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1422 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1440 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1521 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2726 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3668 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3004 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1650 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1500 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1870 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1419 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2003 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1624 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1621 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1837 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1438 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2778 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1405 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1709 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1773 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2719 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1613 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1312 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1603 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1432 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2479 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1576 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2925 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1731 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3725 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1505 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1878 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1462 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1738 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1323 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2636 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1503 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1781 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2919 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2553 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1462 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1784 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1962 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2626 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1456 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1426 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1559 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2958 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2508 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1336 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1981 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2437 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1295 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1508 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1372 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1632 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1314 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1532 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1488 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1608 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1513 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1669 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1435 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1700 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2508 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2815 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2451 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1790 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1574 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1464 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1889 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3011 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1302 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1838 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1292 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1580 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1440 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1711 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1906 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2283 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1163 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1610 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1475 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1733 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1609 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1871 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2572 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2759 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1524 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1420 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1387 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1733 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1618 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2606 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1741 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3406 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1497 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1930 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1486 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1606 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (9445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2372 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1906 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2995 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1395 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1795 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1745 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2763 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2215 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1740 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1963 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1986 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1540 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1855 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1836 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3460 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1839 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2928 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1788 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1375 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1984 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2630 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2003 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1562 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (11394 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1689 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1467 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1891 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1910 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1582 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1733 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1524 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1620 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2955 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2946 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1749 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1638 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1664 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1696 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1528 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3870 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1930 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1542 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1845 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1477 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1994 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1710 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1669 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1920 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1604 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1564 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1652 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1367 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1985 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1461 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1451 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2462 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1432 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3375 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1775 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1800 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1529 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1940 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1455 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1452 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2591 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1919 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2422 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2590 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1760 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1511 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1865 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1504 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1426 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1677 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5066 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1574 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1592 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1571 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1684 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1906 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2817 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1416 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1367 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1663 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2324 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1492 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1531 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1429 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1679 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1516 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1584 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1608 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1414 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1620 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1469 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1669 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2594 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1432 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1412 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1989 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1624 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1688 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1640 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1977 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1442 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1283 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1935 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1491 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1464 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1716 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1868 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1666 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1767 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1778 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2775 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2483 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1822 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3942 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1986 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1402 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1503 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1491 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2535 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1953 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1570 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2089 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1960 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2467 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2618 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1600 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1435 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1643 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1675 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1423 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1755 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1831 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1664 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1594 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1800 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1411 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1474 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1385 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1673 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1769 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1866 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1305 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3827 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1346 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1419 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1607 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1548 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1548 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1661 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1750 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1708 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1510 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1310 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1874 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3687 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1424 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1595 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2528 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1712 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1399 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1622 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1583 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1424 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1586 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1574 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1840 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1576 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1597 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1470 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1672 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5967 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2753 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1295 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3911 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1600 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2157 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1765 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1684 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1500 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1913 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1848 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1714 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1835 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1574 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2775 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1506 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6966 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1758 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1409 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1546 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2569 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1854 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2657 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1883 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2696 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1340 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1717 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2457 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1372 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1602 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1488 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1297 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3687 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2676 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1820 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1570 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1561 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1423 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7339 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1547 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1873 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2597 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1678 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1572 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1355 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1930 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1563 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1504 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2417 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1541 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1653 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2935 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2825 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1438 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1808 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1725 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1283 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1515 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1795 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1421 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1567 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2001 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5860 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1485 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1726 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1657 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1622 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3006 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1630 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4762 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1546 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1985 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1772 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1534 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1746 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1582 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1346 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1402 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1897 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1504 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1610 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2006 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1405 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1807 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1513 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3007 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1500 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1561 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1588 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2258 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1781 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1535 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1495 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1841 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2920 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7935 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1494 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1375 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1862 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1355 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1545 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1292 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1488 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1665 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1557 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1697 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1163 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1486 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1972 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2830 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3381 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1609 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1489 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1754 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1763 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2900 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1842 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1323 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1410 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1940 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2544 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1582 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6712 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1243 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1470 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1517 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1867 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1862 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1799 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1768 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2685 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3825 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1526 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1371 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2552 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1309 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1942 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1613 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1495 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1831 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1547 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1811 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1987 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1452 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1857 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1825 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1567 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1488 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1449 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1451 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2855 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1823 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1895 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1572 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1757 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1515 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1936 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1987 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5404 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1339 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1985 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1409 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1962 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1641 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1516 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1723 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1276 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1704 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1993 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1540 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2480 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2418 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1589 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1758 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1777 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4948 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1505 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1395 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1455 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1957 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1632 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1493 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1603 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1427 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1577 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1804 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2808 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1653 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1427 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1564 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1414 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1537 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1423 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1731 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1408 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1633 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3583 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1656 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1478 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1452 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1565 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1748 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2357 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1452 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1586 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1583 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1243 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1635 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1641 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1973 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1319 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1358 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1736 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1812 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1666 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1458 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3846 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1427 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1856 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1726 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1887 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1472 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1650 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1322 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2580 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1925 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1382 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2756 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1746 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1420 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1563 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5452 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1702 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1586 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1420 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1983 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1518 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2130 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2522 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1529 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1449 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1324 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1322 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1621 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1383 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1829 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1461 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1872 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1729 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2297 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1319 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1505 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1932 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1429 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1950 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1427 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1425 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1554 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1532 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2918 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1510 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1628 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2309 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1774 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2406 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1912 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1851 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1372 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1895 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1480 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1578 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1449 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1953 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1950 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1323 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4946 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1517 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1392 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2429 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2659 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1640 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1717 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2947 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1972 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2333 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1728 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1427 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1829 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1831 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1885 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4585 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1481 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1774 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1294 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1817 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1649 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1614 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1723 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1809 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1605 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1310 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1542 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1526 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3721 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1683 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1654 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1718 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1781 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3765 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1421 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1380 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1510 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1494 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2781 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1524 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1968 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1509 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1805 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1295 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1557 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1336 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1972 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1783 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1936 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1294 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7983 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4504 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1588 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1692 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1701 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1465 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1896 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1850 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1549 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1710 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1460 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1616 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6000 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1621 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1424 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1779 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1514 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1553 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1999 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2007 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1686 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1573 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1571 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1375 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3780 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1358 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1649 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1671 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1770 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1621 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1978 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1587 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1707 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1535 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1660 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2163 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1356 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2935 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1394 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1732 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1587 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1426 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1498 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2382 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1481 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1301 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2326 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1703 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1590 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1615 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1500 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1296 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1769 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1258 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1464 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1816 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1663 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1603 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1511 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1916 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5618 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1449 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2602 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1859 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2356 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1916 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1742 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1623 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2350 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1295 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1577 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2004 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1616 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1847 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1585 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1542 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1314 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1852 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1568 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1615 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2109 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1339 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3683 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1509 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1346 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1461 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1314 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2963 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1590 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1683 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1613 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1624 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1608 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3765 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1463 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1977 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2790 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1482 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1757 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1533 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1546 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1565 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1502 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1513 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1760 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2369 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2453 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2000 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2483 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1395 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1426 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2268 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1707 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1913 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1491 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2354 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (8909 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1382 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1459 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2554 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1586 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1324 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1583 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1652 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1770 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3336 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1545 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2059 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1493 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1416 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1604 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1339 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1465 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1551 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2533 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2800 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1893 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2121 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1957 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2639 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1937 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1822 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1928 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1467 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1897 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1541 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4573 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1356 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1380 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1857 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1760 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2701 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2660 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2538 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1402 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1509 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1163 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1444 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1302 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (8807 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1472 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (8318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1925 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1807 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1432 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1803 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1765 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1864 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1593 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1968 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2546 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1506 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2467 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1339 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1649 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1460 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1622 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1473 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1544 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2536 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1623 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1687 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1818 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1529 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1508 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1680 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1732 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1820 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1455 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1787 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1687 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1829 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1791 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1354 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1921 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1638 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2725 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1460 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1896 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1438 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1656 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1310 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1770 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2747 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1618 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2954 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1698 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1920 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1426 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2479 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1747 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1411 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1633 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1972 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1472 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1603 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1371 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1743 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1430 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1651 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1744 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1762 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1593 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1469 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1601 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1745 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1412 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1982 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1654 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1721 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2791 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1793 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1693 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1666 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1446 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1382 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1521 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1594 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1786 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1677 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1852 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1523 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1544 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1564 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1357 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1434 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1297 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1276 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1889 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1163 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1866 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1821 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1745 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1394 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1851 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1521 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1544 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1355 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3642 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1904 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3577 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2410 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1995 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1906 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1478 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3878 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3871 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1575 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1559 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1567 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2811 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1816 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1268 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1596 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1735 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1543 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1529 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1552 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1358 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1700 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2370 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1356 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1649 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1511 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1873 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1498 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1889 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1822 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1479 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1598 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1737 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1391 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1474 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1391 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1575 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1414 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1430 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1489 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2021 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1346 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2610 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1382 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2926 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2667 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1517 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1544 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1297 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1323 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1446 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1768 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1628 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3727 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2802 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1696 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1466 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1970 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1632 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1709 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1413 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4655 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2354 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1382 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3904 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2582 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1564 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1629 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1728 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1532 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1657 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1592 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1557 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1660 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2727 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1319 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1458 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1314 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1603 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1744 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1268 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1545 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1904 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3558 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4031 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1593 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1268 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1676 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1423 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4897 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1704 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1473 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2427 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2662 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1668 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1721 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1609 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2363 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1465 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1525 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2560 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1506 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1507 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1537 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1408 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1420 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4507 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2421 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1392 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1869 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5566 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2849 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2423 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1682 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1492 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1923 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1268 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1493 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1848 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1482 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1701 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1517 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1472 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3614 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1525 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1616 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2388 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1477 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1731 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1560 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1618 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1993 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1485 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2414 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1479 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2355 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1906 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1367 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2011 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1644 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1975 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1490 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2018 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1597 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2419 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2020 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1832 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1944 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2404 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2914 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1595 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1670 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1312 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1437 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1493 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1456 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1597 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1514 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1432 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1870 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2689 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1931 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1572 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (8765 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1430 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1312 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1377 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1488 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1558 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1292 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1639 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1705 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1292 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2619 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1545 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2538 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1835 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1705 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2808 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1472 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2832 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1292 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1924 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1544 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2021 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1413 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1894 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2781 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2754 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1745 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2369 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1710 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1822 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1637 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1837 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1553 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1496 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1497 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1528 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1622 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1619 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1577 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1526 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1462 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1636 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1326 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4821 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1465 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1508 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1997 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1323 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1319 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1710 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1576 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1840 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1432 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1757 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1243 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1654 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1893 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1516 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1629 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1865 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1276 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1383 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1466 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1442 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1963 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1354 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3917 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1568 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2444 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1724 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1968 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2017 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1526 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3620 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1620 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1470 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1408 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1696 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1736 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1542 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1550 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1549 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1551 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2613 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2657 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1778 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1543 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1644 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1786 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1992 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1413 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1663 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1549 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1529 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1792 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1358 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1873 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1578 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1909 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1409 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1541 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2103 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1953 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2769 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1601 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1346 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2683 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6550 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5494 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1649 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1759 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2557 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1309 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1309 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1694 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1601 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1416 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1319 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1818 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1596 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1461 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1480 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4005 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1886 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1276 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1788 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3457 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1842 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1453 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1509 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1745 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1377 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1879 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1562 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1560 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1922 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1601 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1570 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1604 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1455 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1437 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1731 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1485 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2834 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1414 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1470 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1541 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1915 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1631 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2470 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1535 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1435 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1416 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1531 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1402 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1422 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1661 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1412 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2666 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1380 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1892 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1399 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1791 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1462 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1978 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1803 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1355 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1585 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2608 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2345 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2408 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2612 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1566 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1830 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1593 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1363 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1948 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1762 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1685 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1310 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1589 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1591 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1547 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1617 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1897 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1310 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1370 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1596 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1742 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1541 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1764 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1371 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1677 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1864 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1753 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1828 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1617 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1820 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1754 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1312 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1536 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1546 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1555 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (10183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3616 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1619 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1292 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3520 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1529 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1702 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1395 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1946 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1594 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1372 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1741 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1823 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1522 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1709 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1957 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1961 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1493 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1319 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1823 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1911 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1963 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1998 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1640 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2018 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1579 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1450 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1788 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1575 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1657 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2546 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2502 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1427 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1294 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1310 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1797 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1416 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2325 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1302 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1529 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2520 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2388 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1498 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1632 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1716 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1953 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1505 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2700 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1554 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1930 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2399 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1613 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1425 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1881 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1757 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1626 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2553 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1295 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1641 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1768 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1742 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1703 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1760 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1688 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1462 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1784 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1691 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2614 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1458 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (12404 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2527 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1406 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1495 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2793 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1562 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1953 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1590 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1854 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1666 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1755 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1715 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2544 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1782 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2290 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1367 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3457 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1556 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1652 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1783 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1452 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1597 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1620 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1395 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1998 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1947 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1149 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1276 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1614 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1314 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1314 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1405 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1796 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1402 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1697 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1964 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1541 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1904 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1846 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1659 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1944 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2432 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1552 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2418 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1477 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1444 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1712 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1804 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1855 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1548 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1625 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1393 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1682 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1753 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1507 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1672 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2264 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1751 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2350 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1728 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1633 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2276 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2059 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1782 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1879 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1612 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1510 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3773 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2215 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2602 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1679 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2521 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1799 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1691 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1468 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1339 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3585 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3743 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4002 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1424 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5852 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1395 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1675 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1450 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1624 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1741 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2381 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1463 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1845 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1676 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1551 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1593 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2946 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1470 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1587 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1689 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1394 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1819 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1929 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4540 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1276 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1567 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1732 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1731 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1432 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1715 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1597 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1459 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2295 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1429 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1799 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1385 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3575 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1358 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2996 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1609 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1504 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1891 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1719 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1702 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2460 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1462 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1516 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1305 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1297 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2367 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1653 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1865 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3372 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1684 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1884 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1567 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1913 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1699 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1414 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1457 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1495 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2717 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2346 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1618 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1697 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2017 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7697 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2017 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1759 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1951 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1295 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1467 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1538 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5459 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1517 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1371 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1765 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1574 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1258 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1575 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1786 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1462 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1438 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1412 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1817 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1962 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1550 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3570 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1464 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1420 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1849 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1633 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2836 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2397 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2458 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1369 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1756 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1866 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2616 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1696 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1691 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1537 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2821 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1821 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2854 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2938 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1953 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1411 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1528 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1559 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1777 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2455 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2013 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1595 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1461 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1312 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2372 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1529 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1716 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1739 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1721 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1517 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1482 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1717 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4309 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1736 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1732 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1932 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1870 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2624 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1662 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1546 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1482 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2015 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1754 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1792 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2593 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1604 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1816 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1413 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1896 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2645 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1477 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2004 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1538 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1808 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1522 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1682 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1356 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1513 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1605 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2534 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1823 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1704 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1792 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1568 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2297 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1600 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1735 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1601 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2628 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1916 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1779 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2449 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2521 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1691 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2783 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1808 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2708 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1478 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1380 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1500 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1457 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2741 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1749 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1963 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2417 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2590 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1628 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1666 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1666 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1666 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1666 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1666 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1421 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1458 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1463 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1865 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5868 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3008 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1494 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1849 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1452 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1644 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1722 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1826 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2392 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3786 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1830 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1658 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2301 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1504 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2895 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1838 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1305 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1404 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1722 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1413 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1505 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1562 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1644 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2991 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (9766 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1908 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3007 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1296 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1784 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1939 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1425 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1392 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2525 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1425 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1748 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2768 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2603 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1297 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2606 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1492 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1864 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1735 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1887 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1590 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1751 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2431 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1461 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2394 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1715 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1324 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1354 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1657 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1659 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1821 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1574 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1485 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1590 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1573 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1621 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1458 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1566 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1949 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1500 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1808 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1429 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1591 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1404 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2568 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1369 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1500 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1920 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1461 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1681 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1560 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1406 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1480 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1412 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1850 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1721 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3618 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1618 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1775 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1751 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1375 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1807 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1540 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1770 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1511 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1994 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1850 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1757 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1402 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1802 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2385 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2623 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2999 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1453 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1533 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1437 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1887 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2979 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1434 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1858 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1535 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1243 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1437 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2268 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1461 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1899 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1995 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1435 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3312 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1468 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1815 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1343 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1723 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1739 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1712 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1741 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1952 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2494 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1465 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1701 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1623 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1444 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1945 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1539 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1424 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1830 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1477 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1638 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1712 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1822 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1258 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (9449 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1848 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1507 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1549 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1584 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1688 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1455 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1833 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2290 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1382 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1661 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1393 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1745 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2376 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2921 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1506 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1319 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1570 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1753 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1456 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1962 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1600 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1542 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1276 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1604 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2910 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1650 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6820 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1406 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1776 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2009 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1427 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1854 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1866 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1382 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1952 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2453 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1832 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2650 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1976 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1587 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1450 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1953 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1641 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1667 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1446 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1163 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7005 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1399 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1557 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1790 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2024 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1417 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1258 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1524 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1671 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1667 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1636 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1982 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2395 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1506 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1593 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3012 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1660 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1662 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3022 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1642 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1433 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1832 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1998 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1418 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2221 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1469 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1859 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1369 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1554 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1258 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1283 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1426 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1319 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1258 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1484 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1595 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1625 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1492 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1760 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2693 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1716 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1276 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1618 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1619 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1661 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1529 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1977 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1414 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1803 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1387 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1930 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1834 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1592 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1356 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1661 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2016 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3817 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1618 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1568 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1526 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3371 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1956 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1671 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3016 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1732 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1394 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2000 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1807 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1865 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1834 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1769 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1495 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2719 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1986 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1850 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1586 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1367 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1314 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1456 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1610 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1989 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1909 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1617 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1302 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1647 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1462 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1536 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1865 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1906 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2012 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1826 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1813 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1418 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2825 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1322 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3609 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1790 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1340 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2008 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1459 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1801 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1305 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3296 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2562 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2295 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2988 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1930 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1468 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1574 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3846 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2645 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1745 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1821 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1592 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1268 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1630 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1472 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2163 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1668 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1393 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1596 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2847 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1305 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2899 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2412 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1434 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1464 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1731 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1537 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1302 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2464 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1879 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1679 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1426 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1603 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1467 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2023 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1708 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1498 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1433 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1438 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2323 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3914 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1533 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2662 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1674 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1820 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1420 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1462 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1743 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1481 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1326 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1294 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1536 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1517 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4478 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1802 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1793 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1786 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2692 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2696 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1782 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1592 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2600 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4546 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1614 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1984 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1652 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3750 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1726 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2381 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1968 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1582 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2001 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1302 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5593 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1712 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1534 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1451 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1163 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2716 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2535 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1572 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2597 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5464 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1559 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1490 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1632 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2808 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1820 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2895 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2016 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1343 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1163 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1309 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1516 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1568 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3015 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3584 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3866 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3735 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1743 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2567 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5312 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1577 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1702 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1336 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1581 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2964 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2862 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1882 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2444 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1535 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1526 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1514 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1509 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2310 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1615 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3722 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1467 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1642 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1628 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1440 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1698 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2961 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1394 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2869 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1878 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1574 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1856 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3634 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1490 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1442 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1715 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1561 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1908 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1412 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1544 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1322 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1243 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3577 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1371 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2417 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1790 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4018 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1319 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4406 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1720 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1636 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1473 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1423 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1509 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1712 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1733 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1465 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1812 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1701 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1484 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1603 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1475 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1778 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1738 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1309 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1952 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1647 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1343 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1336 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1532 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1646 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1671 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1601 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1603 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1712 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1972 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1446 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1408 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1422 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1413 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1843 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1690 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1582 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1717 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1358 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1460 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1823 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1412 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1877 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1620 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1503 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2518 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1916 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1598 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1540 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1559 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1992 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1468 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1484 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1393 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2845 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1732 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1824 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1779 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1696 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1725 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1656 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1814 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1813 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1678 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3296 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1642 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1669 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1752 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1731 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1461 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2277 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1703 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2350 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1567 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1597 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1627 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1552 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1665 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2314 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1498 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1442 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1795 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1675 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1786 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3853 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1640 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6730 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1601 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1387 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3952 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1663 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1305 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1632 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2761 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1268 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1310 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2016 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1626 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3008 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1726 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1986 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1639 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1478 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1877 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2797 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1596 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1731 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1323 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1629 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1689 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1525 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1385 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1734 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1608 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2718 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1786 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6717 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1478 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1579 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1543 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1879 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2267 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2303 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1741 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2437 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1654 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1516 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1457 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1463 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1413 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3715 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1377 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1592 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1553 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1955 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1295 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1521 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1346 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1988 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1616 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1479 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1305 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1647 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1488 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1564 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1357 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1781 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2442 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1673 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1627 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1540 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1742 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1721 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1893 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1949 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1538 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1593 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4504 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1530 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1947 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1900 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1453 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1599 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1545 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1555 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1660 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1640 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1539 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1677 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1793 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6900 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1416 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1598 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1717 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1591 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1268 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1524 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1460 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1573 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1680 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1565 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2821 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1707 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1742 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1576 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1850 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2952 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1573 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1472 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1617 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1979 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1879 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1777 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1412 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1380 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1468 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1725 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1417 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1545 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1811 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1866 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1724 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1530 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2864 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1630 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1841 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1543 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1514 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1355 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1631 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1470 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1644 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1707 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1696 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1700 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1975 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1404 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1777 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1492 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1727 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1464 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1541 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1612 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1918 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1986 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1493 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1760 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1788 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2011 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1536 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1581 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1504 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2292 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1656 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1525 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1694 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2499 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1595 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1558 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1875 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1559 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (8099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1588 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1753 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1660 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1294 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1446 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1690 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1738 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1301 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1422 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1896 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1926 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3874 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3641 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1784 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1861 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1891 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2934 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1581 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2841 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1408 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1528 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1783 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1442 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1943 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1947 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6967 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1477 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2809 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1741 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1258 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1545 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2641 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2554 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1470 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1815 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1505 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1937 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1861 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1898 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1984 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1599 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1394 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1866 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1563 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1450 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1586 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1745 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1582 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1688 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1820 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1733 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1409 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1985 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1425 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1296 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1326 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2636 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1787 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1354 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1970 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1322 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1922 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1893 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1969 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1402 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1498 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1620 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7350 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1493 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1735 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1945 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1674 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1516 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1523 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1297 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1827 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1653 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1466 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1516 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1735 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1701 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3404 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2708 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1377 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2435 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1612 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2968 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1702 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1983 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1477 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1466 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1418 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1618 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1850 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1564 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2996 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1600 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1997 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1802 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1893 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1513 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2507 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1669 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1243 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1808 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2275 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1740 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1569 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1892 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1656 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1594 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1766 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5982 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1758 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1548 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1382 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1667 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1667 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1737 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1540 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2795 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1425 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2392 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1988 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1388 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2684 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1339 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2160 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2464 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1449 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1440 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1450 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1587 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1858 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1429 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1477 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1921 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1393 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1375 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1505 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1446 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1644 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1523 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1993 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1515 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2087 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1343 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1296 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1422 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1470 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3813 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1878 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2007 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1851 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1982 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1908 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1508 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1854 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1915 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2474 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2828 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1779 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1766 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1668 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1781 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1481 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1882 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1429 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1354 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1613 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1399 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1814 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1599 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1478 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2913 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1859 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2302 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1837 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1714 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3660 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1876 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1716 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1961 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1459 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1724 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1555 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1840 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1743 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1416 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1639 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1694 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1682 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1431 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1464 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1986 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1489 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1363 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1385 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1571 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1392 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1488 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2737 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1475 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1295 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1552 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1670 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1910 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1574 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2007 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1526 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2309 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1554 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1510 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5602 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1675 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1450 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1410 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1399 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1904 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1586 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1924 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1814 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1484 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1700 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1890 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1354 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1568 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3797 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1451 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1419 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1326 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1698 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1981 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1954 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1968 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1729 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3645 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1691 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1477 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2868 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1460 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1560 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1852 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2393 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1746 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1690 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1782 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1815 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1449 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1301 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1886 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1540 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1463 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1710 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1911 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1528 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1466 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1939 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1715 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1627 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1302 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1302 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1572 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1576 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1442 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1668 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1354 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1581 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2526 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2690 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1821 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3302 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1295 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1636 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1934 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1606 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1648 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2787 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1970 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2634 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1346 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1438 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1419 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1414 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1450 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1641 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1663 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1481 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1452 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1590 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1477 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1578 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2565 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1370 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1776 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1762 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1481 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2518 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1418 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1453 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1970 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1963 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1411 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1690 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1738 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1803 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4024 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1492 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1369 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1629 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1511 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1568 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1716 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (8100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4325 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1710 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1397 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1717 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1713 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1848 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2516 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1777 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1519 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1694 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1982 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1496 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2010 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1721 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2541 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1625 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1408 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1853 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1701 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3724 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1711 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1711 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1473 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1459 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1732 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1506 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1887 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1538 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1624 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1787 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1878 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1675 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1899 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1635 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1522 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1966 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1523 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2664 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1935 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1885 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1464 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1968 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1921 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1301 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1556 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1297 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1750 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1563 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1689 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2875 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2764 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1619 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1357 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1657 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1621 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1726 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1628 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1740 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1693 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2007 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1877 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1309 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1621 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1643 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1551 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1728 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1809 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1904 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1419 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1864 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1570 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1557 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1444 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1473 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1548 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1442 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1532 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2408 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1646 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1636 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2009 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1868 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1421 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1760 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1623 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2544 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1474 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1461 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1958 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2456 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3935 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1433 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1702 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1885 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2408 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1547 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1703 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1606 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2292 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1922 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1674 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1715 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2717 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1684 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1479 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1555 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1469 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1498 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1503 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1891 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2481 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1569 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1446 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1991 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1531 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1395 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2848 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1584 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1493 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2455 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5542 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1747 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1548 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1758 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2559 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1494 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1479 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1854 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1301 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1499 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1756 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1518 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1728 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1660 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1339 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1906 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1781 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1870 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1765 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4009 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1560 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1633 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1515 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1684 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2268 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1572 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1518 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1463 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1502 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1517 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1569 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1800 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2625 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1982 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2511 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1550 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1393 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7277 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1657 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1838 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1465 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1576 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1674 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1522 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1695 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1336 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1561 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2297 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1355 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1472 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2606 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1757 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1858 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1685 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1530 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1646 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1842 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1609 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1385 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1555 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1547 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1797 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1659 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1550 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1646 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1559 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1367 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1408 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1931 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2606 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1520 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1419 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1898 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2815 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1586 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1640 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2431 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2860 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1788 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2008 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1754 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1500 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1838 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1995 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1492 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1687 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1670 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1440 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1659 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1591 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1542 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1910 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2024 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1578 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1385 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1843 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1826 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1617 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1989 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1417 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2308 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1542 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2277 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1750 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1859 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1904 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7458 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1339 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1346 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1468 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1567 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1563 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1449 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1417 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1824 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2608 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1465 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2653 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3985 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1363 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1422 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1681 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1625 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1494 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1772 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1446 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1545 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1425 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1734 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2646 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2657 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2549 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1641 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1932 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1674 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1800 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1929 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1560 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1603 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1689 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1630 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1355 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2201 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1551 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1650 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1394 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1365 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1850 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1503 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1597 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6562 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1511 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1319 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1309 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1532 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1657 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1355 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1768 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1653 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1355 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1430 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1544 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1544 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1555 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1422 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1517 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1444 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1771 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2644 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1818 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2780 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2326 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1688 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2291 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1538 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1499 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1605 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1488 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1372 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2821 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5812 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1527 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1791 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1480 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1518 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2000 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1775 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2760 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1607 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1717 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1729 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2586 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1995 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1665 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2517 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1283 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3426 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1511 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1561 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1429 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1927 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1622 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1673 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1682 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1408 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1503 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3024 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1394 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1578 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1707 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1652 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1855 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1459 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1634 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1686 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1473 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2586 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1873 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3419 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1481 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1386 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1613 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2717 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1933 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1507 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1627 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1790 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5536 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2512 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1426 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2472 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1409 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1382 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1597 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2604 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1701 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3740 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1810 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3243 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1530 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1470 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1844 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1530 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1412 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2469 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7109 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6607 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1617 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1855 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1466 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1610 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1656 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2407 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5556 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1417 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1561 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1421 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1292 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2295 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1602 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1511 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2483 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1772 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1371 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1592 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1412 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1587 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1618 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1634 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1535 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1781 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2367 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2883 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1912 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1538 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1976 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1631 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1408 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1668 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1657 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1343 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2496 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1739 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1996 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1631 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1677 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1431 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1577 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1627 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1394 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1319 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1380 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5001 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1408 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1458 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1654 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2015 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1375 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1533 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1698 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2834 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1469 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1427 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1701 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1833 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2462 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4879 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1839 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2253 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1807 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1503 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1587 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1737 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1489 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1566 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1692 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1709 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1286 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1890 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1444 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1690 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1587 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1552 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1418 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1369 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1793 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1409 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1823 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1516 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1496 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1715 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2155 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5324 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1715 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3518 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1640 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1469 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1540 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1412 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1468 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1884 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1483 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1607 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1720 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1557 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1566 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1968 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1818 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1601 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1956 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1470 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1575 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1698 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1565 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1969 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1673 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1387 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1879 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1405 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1444 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1486 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1594 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1959 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1929 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2632 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4764 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1618 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2994 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1932 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1418 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2006 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1369 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1846 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1632 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1897 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2613 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1666 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2635 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1620 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1693 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1917 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2900 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1372 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1790 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1423 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1618 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1474 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1726 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1698 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2564 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2472 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2768 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2385 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1480 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1425 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1786 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2542 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1455 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2975 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1492 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1577 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1514 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1417 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1837 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1682 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2886 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1550 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2743 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1479 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1515 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1460 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1490 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1856 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2930 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2362 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1711 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1309 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1627 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1301 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1509 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1763 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3246 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1642 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2006 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3455 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1600 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1356 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1709 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1816 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1541 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1994 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1343 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1600 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1385 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2491 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1322 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1363 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1891 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1670 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1292 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1735 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2349 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1582 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1617 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2613 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1548 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7574 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1526 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1543 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1404 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1438 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2588 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1413 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1297 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1517 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1296 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1690 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1297 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1525 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1414 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1356 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1545 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1752 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1410 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2685 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1312 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1392 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1641 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1305 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2780 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1745 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1840 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1603 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1925 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1542 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1602 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1383 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2792 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2415 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1915 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1341 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3793 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1429 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1557 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1678 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1742 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2965 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1514 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1573 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2661 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3223 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1800 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1500 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1426 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2309 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1531 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1685 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1728 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1391 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1777 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4654 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1449 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1571 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1700 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1481 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1556 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1432 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1682 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1892 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3748 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1683 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1434 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1243 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1417 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1466 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3580 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3311 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1422 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2842 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1367 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1370 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1781 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1482 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1484 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1404 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1913 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2040 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1544 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1314 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1497 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1992 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2891 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1572 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2677 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1439 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1323 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2491 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1905 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2015 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2559 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2495 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1489 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1648 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2290 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1898 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1560 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1460 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1934 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1732 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2419 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1412 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3615 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1463 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1268 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1412 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1949 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1547 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2388 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1464 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3653 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2183 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2532 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1375 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2531 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1406 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1391 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1830 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1342 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2017 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1248 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1592 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2308 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1464 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1488 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1610 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1682 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1538 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2929 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1471 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1550 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1485 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1607 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1423 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1294 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1430 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1681 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2533 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1477 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2529 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1546 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1786 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1684 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2081 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1497 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1628 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1554 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2640 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1427 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1457 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1663 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1383 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2324 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4336 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1331 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1537 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1478 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1792 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1535 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1562 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1731 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1601 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2510 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3600 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1918 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1568 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3951 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1303 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1579 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1436 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1604 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1510 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2691 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2612 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1292 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1769 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1675 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1563 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1464 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1434 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1383 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1568 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3918 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1339 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2456 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1273 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1894 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1506 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1343 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2857 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1328 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1608 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1553 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1504 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1774 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2291 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1494 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1912 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1473 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1513 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1656 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2849 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7472 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2561 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1754 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2475 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2149 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4337 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2736 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3628 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1789 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2499 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1385 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1243 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1356 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1649 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1543 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1847 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1268 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1672 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1971 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5815 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1385 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1768 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1693 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1657 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1593 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2612 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2228 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1653 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1483 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1843 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1558 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1380 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1417 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1753 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1870 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1682 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1506 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2001 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2763 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1849 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1694 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1736 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1828 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1757 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2406 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1282 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1785 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1446 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3309 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1385 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1422 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1578 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3089 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1991 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1407 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1360 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2195 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1534 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1596 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2612 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1198 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2029 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1409 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1496 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1753 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1283 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2191 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1740 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1453 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1935 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1617 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1546 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1571 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1438 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1521 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1610 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2320 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3811 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1851 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1567 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2274 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2458 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1999 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1394 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1943 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2856 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2003 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2433 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3697 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1605 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1705 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1541 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1811 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1240 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1768 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1795 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1672 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1566 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1437 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1585 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1276 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1541 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1470 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1437 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1791 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2327 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1909 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2990 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1504 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2053 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1495 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1514 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1781 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1556 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1526 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1710 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1946 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1808 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1765 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3764 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1406 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2014 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1696 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1450 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1264 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1380 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1548 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1434 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1447 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1706 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2064 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1644 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1788 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1523 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1907 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (5026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1824 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1754 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3252 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1689 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1656 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2523 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1526 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1163 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3677 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1656 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2571 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1486 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1866 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2699 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2115 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2490 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3728 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3869 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1748 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1706 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1370 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1698 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1472 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1920 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1661 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2371 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1895 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1571 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2433 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1802 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1434 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1344 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (7493 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1258 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2798 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1229 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2500 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1646 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2296 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1918 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1454 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1536 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1536 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1269 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2463 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1896 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3880 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1994 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1976 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1703 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1715 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1686 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1501 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2319 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1665 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1459 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2140 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2154 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2122 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1319 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1592 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1399 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1533 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1568 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1915 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1856 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1722 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1553 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1897 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1867 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1883 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1711 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1529 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1363 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2131 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1493 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4576 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1428 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1294 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1336 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2384 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2322 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1586 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1473 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1496 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1775 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1268 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1561 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2635 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1943 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2086 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2461 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1687 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1411 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2107 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2460 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1849 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1854 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1478 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1796 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1455 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2401 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1934 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1771 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2724 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1628 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1954 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3458 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1956 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2069 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1415 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1501 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1371 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1319 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1445 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1616 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2299 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1466 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1418 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1366 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1551 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1944 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1965 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1736 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1792 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1727 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1395 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1962 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1411 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2334 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1354 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2945 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1467 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1679 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2016 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2166 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1627 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1244 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3356 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1294 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1522 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1420 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1555 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1370 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1641 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1637 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1295 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1727 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1644 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1300 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1608 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1387 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "#https://pytorch.org/hub/huggingface_pytorch-pretrained-bert_gpt2/\n",
    "def tokenize(row):\n",
    "    tokens = tokenizer.encode(f\"\"\"$CATEGORY$\n",
    "{row['category']}\n",
    "$CATEGORY$\n",
    "$TITLE$\n",
    "{row['title']}\n",
    "$TITLE$\n",
    "$SUBTITLE$\n",
    "{row['subtitle']}\n",
    "$SUBTITLE$\n",
    "$BODY$\n",
    "{row['text']}\n",
    "$BODY$\"\"\")\n",
    "    tokens_len = len(tokens)\n",
    "    if tokens_len > 500: #1024\n",
    "        return np.nan\n",
    "    else:\n",
    "        padding_len = 500 - tokens_len\n",
    "        padding = np.repeat(0, padding_len)\n",
    "        return np.concatenate((tokens, padding), axis=0).tolist()\n",
    "\n",
    "df['tokens'] = df.apply(tokenize, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22592, 7)\n",
      "entertainment     6155\n",
      "politics          4182\n",
      "comedy            2680\n",
      "weird news        1505\n",
      "sports            1482\n",
      "queer voices       911\n",
      "black voices       821\n",
      "the worldpost      727\n",
      "crime              683\n",
      "media              626\n",
      "women              524\n",
      "tech               385\n",
      "world news         357\n",
      "arts & culture     345\n",
      "science            280\n",
      "latino voices      269\n",
      "business           265\n",
      "religion           155\n",
      "green              148\n",
      "impact              85\n",
      "education            7\n",
      "Name: category, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>The 2018 FIFA World Cup starts June 14 in Russ...</td>\n",
       "      <td>05/26/2018</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>[720, 34, 6158, 38, 15513, 3, 198, 298, 1425, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>Love actually turned to matrimony for Hugh Gra...</td>\n",
       "      <td>05/26/2018</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>[720, 34, 6158, 38, 15513, 3, 198, 298, 1425, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "1  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2    Hugh Grant Marries For The First Time At Age 57   \n",
       "\n",
       "                                            subtitle       category  \\\n",
       "1                           Of course it has a song.  entertainment   \n",
       "2  The actor and his longtime girlfriend Anna Ebe...  entertainment   \n",
       "\n",
       "                                                text        date  \\\n",
       "1  The 2018 FIFA World Cup starts June 14 in Russ...  05/26/2018   \n",
       "2  Love actually turned to matrimony for Hugh Gra...  05/26/2018   \n",
       "\n",
       "                                                 url  \\\n",
       "1  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "2  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
       "\n",
       "                                              tokens  \n",
       "1  [720, 34, 6158, 38, 15513, 3, 198, 298, 1425, ...  \n",
       "2  [720, 34, 6158, 38, 15513, 3, 198, 298, 1425, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "print(df.category.value_counts())\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['url', 'tokens', 'category']].to_csv('datasets/medium_news_training.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
